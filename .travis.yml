sudo: False

language: python

matrix:
  fast_finish: true
  include:
    - python: 2.7
      env: SPARK_VERSION=1.4
    - python: 2.7
      env: SPARK_VERSION=1.5
    - python: 3.4
      env: SPARK_VERSION=1.4
    - python: 3.4
      env: SPARK_VERSION=1.5
    - python: 3.5
      env:
    - python: 2.7
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas" SPARK_VERSION=1.5
    - python: 3.4
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas" SPARK_VERSION=1.5
    - python: 3.5
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas"
  allow_failures:
    - python: 2.7
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas" SPARK_VERSION=1.5
    - python: 3.4
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas" SPARK_VERSION=1.5
    - python: 3.5
      env: PANDAS_VERSION="git+https://github.com/pydata/pandas"

addons:
  postgresql: "9.3"

services:
    - mongodb
    - mysql

install:
  # Install conda
  - wget http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - conda config --set always_yes yes --set changeps1 no
  - conda update conda

  # Install dependencies
  - conda create -n odo python=$TRAVIS_PYTHON_VERSION pytest numpy pandas sqlalchemy
  - conda install -n odo h5py pip cython bcolz coverage networkx toolz multipledispatch
  - conda install -n odo pytables paramiko boto boto3 bokeh pymysql
  - if [ -n "$PANDAS_VERSION" ]; then conda remove -n odo pandas; fi
  - source activate odo

  # datashape
  - pip install git+git://github.com/blaze/datashape.git

  # Install various deps
  - conda uninstall toolz
  - pip install -U toolz sas7bdat psycopg2 dill 'pymongo<3' sqlalchemy-redshift
  - pip install git+git://github.com/blaze/dask.git#egg=dask-dev[complete]
  - if [ -n "$PANDAS_VERSION" ]; then pip install $PANDAS_VERSION; fi

  # install pyspark
  - if [[ $TRAVIS_PYTHON_VERSION == '2.7' || $TRAVIS_PYTHON_VERSION == '3.4' ]]; then conda install spark=$SPARK_VERSION -c blaze -c https://conda.binstar.org/blaze/channel/dev -c anaconda-cluster; fi

# Before_script section stolen from fabric
# See license https://github.com/fabric/fabric/blob/master/LICENSE
before_script:
  # Allow us to SSH passwordless to localhost
  - ssh-keygen -f ~/.ssh/id_rsa -N ""
  - cp ~/.ssh/{id_rsa.pub,authorized_keys}
  # Creation of an SSH agent for testing forwarding
  - eval $(ssh-agent)
  - ssh-add
  - "mongo admin --eval 'db.runCommand({setParameter: 1, textSearchEnabled: true});'"
  - mysql -e "create database if not exists test;" -u root
  - psql -c "create database test;" -U postgres
  - sleep 15

script:
  - conda list numpy
  - py.test -v --doctest-modules --doctest-ignore-import-errors odo

notifications:
  email: false
